å¥½çš„ï¼Œæˆ‘ä»¬è¿›å…¥ç¬¬å››é˜¶æ®µï¼Œå¯¹æ•°æ®æŒä¹…åŒ–å’Œè¡¥æ°´å±‚è¿›è¡Œæ ¸å¿ƒæ”¹é€ ï¼Œä»¥æ”¯æŒå¤šç”¨æˆ·å…ƒæ•°æ®ã€‚

è¿™æ˜¯ä¸€ä¸ªå…³é”®çš„æ­¥éª¤ï¼Œå®ƒå°† Git ç‰©ç†å±‚é¢çš„å¼•ç”¨ç»“æ„ï¼ˆ`refs/.../<user_id>/...`ï¼‰ä¸ SQLite é€»è¾‘å±‚é¢çš„æ•°æ®æ¨¡å‹è¿æ¥èµ·æ¥ï¼Œä¸º UI å®ç°å¤šç”¨æˆ·å¯è§†åŒ–å¥ å®šåŸºç¡€ã€‚

## feat(engine): æ‰©å±•æ•°æ®æ¨¡å‹ä¸è¡¥æ°´å™¨ä»¥æ”¯æŒæ‰€æœ‰æƒ

### ç”¨æˆ·éœ€æ±‚
æ ¹æ® `Quipu Sync åŠŸèƒ½å¼€å‘ä»»åŠ¡åˆ—è¡¨`ï¼Œéœ€è¦æ‰§è¡Œä»»åŠ¡ 4.1, 4.2 å’Œ 4.3ï¼š
1.  **æ‰©å±•æ•°æ®æ¨¡å‹**: åœ¨ `quipu-interfaces` çš„ `QuipuNode` ä¸­å¢åŠ ä¸€ä¸ªå¯é€‰çš„ `owner_id` å­—æ®µã€‚
2.  **å‡çº§æ•°æ®åº“ Schema**: åœ¨ `quipu-engine` çš„ `nodes` è¡¨ä¸­å¢åŠ  `owner_id` åˆ—ï¼Œå¹¶æ›´æ–°ç›¸åº”çš„å†™å…¥æ–¹æ³•ã€‚
3.  **é‡æ„ Hydrator**: ä½¿è¡¥æ°´å™¨èƒ½å¤Ÿä» Git å¼•ç”¨çš„è·¯å¾„ä¸­è§£æå‡º commit çš„æ‰€æœ‰è€… (`owner_id`)ï¼Œå¹¶å°†å…¶å­˜å…¥æ•°æ®åº“ã€‚

### è¯„è®º
è¿™æ˜¯å®ç°â€œå¤šç»´å¹³è¡Œå®‡å®™â€æ¶æ„åœ¨æ•°æ®å±‚é¢é—­ç¯çš„æ ¸å¿ƒå·¥ä½œã€‚é€šè¿‡å°† `owner_id` å¼•å…¥æ•°æ®æ¨¡å‹å’Œæ•°æ®åº“ï¼Œæˆ‘ä»¬èµ‹äºˆäº†æ¯ä¸ªå†å²èŠ‚ç‚¹æ˜ç¡®çš„å½’å±ã€‚è¿™ä½¿å¾— `Hydrator` çš„è§’è‰²ä»ä¸€ä¸ªç®€å•çš„â€œæ•°æ®æ¬è¿å·¥â€å‡çº§ä¸ºèƒ½å¤Ÿç†è§£åˆ†å¸ƒå¼å…ƒæ•°æ®çš„â€œä¿¡æ¯æ•´åˆå™¨â€ï¼Œä¸ºåç»­åœ¨ UI å±‚å®ç°æŒ‰ä½œè€…ç€è‰²ã€è¿‡æ»¤ç­‰é«˜çº§åŠŸèƒ½æä¾›äº†åšå®çš„æ•°æ®åŸºç¡€ã€‚

### ç›®æ ‡
1.  åœ¨ `QuipuNode` (interfaces) ä¸­æ·»åŠ  `owner_id` å±æ€§ã€‚
2.  åœ¨ `sqlite_db.py` (engine) ä¸­ï¼Œæ›´æ–° `nodes` è¡¨çš„ `CREATE` è¯­å¥å’Œ `batch_insert_nodes` çš„ `INSERT` è¯­å¥ä»¥åŒ…å« `owner_id`ã€‚
3.  ä¿®æ”¹ `git_db.py` ä¸­çš„ `get_all_ref_heads` æ–¹æ³•ï¼Œä½¿å…¶èƒ½è¿”å› commit å“ˆå¸ŒåŠå…¶æ¥æºçš„ ref åç§°ã€‚
4.  å½»åº•é‡æ„ `hydrator.py` (engine)ï¼Œä½¿å…¶èƒ½å¤Ÿè§£æ ref åç§°ä»¥æå– `owner_id`ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯ä¼ é€’ç»™æ•°æ®åº“ã€‚
5.  è°ƒæ•´ `state_machine.py` ä¸­çš„ `align` æ–¹æ³•ï¼Œä»¥åœ¨è°ƒç”¨è¡¥æ°´å™¨æ—¶æä¾›å¿…è¦çš„ `user_id` ä¸Šä¸‹æ–‡ã€‚

### åŸºæœ¬åŸç†
-   **æ‰€æœ‰æƒæºå¤´**: `owner_id` çš„å”¯ä¸€äº‹å®æ¥æºæ˜¯ Git ref çš„è·¯å¾„ã€‚ä¾‹å¦‚ï¼Œæ¥è‡ª `refs/quipu/remotes/origin/alice/heads/...` çš„ commitï¼Œå…¶æ‰€æœ‰è€…å³ä¸º `alice`ã€‚å¯¹äº `refs/quipu/local/heads/...`ï¼Œå…¶æ‰€æœ‰è€…æ˜¯å½“å‰æœ¬åœ°é…ç½®çš„ `user_id`ã€‚
-   **æ•°æ®æµ**: `git for-each-ref` -> `Hydrator` (è§£æ ref è·¯å¾„) -> `(commit_hash, owner_id)` å…ƒç»„ -> `SQLite nodes è¡¨`ã€‚
-   **è§£è€¦**: `Hydrator` è´Ÿè´£ä» Git åŸå§‹æ•°æ®ä¸­æå–å¹¶ä¸°å¯Œå…ƒæ•°æ®ï¼Œ`SQLiteHistoryReader` åˆ™ç›´æ¥æ¶ˆè´¹è¿™äº›å¤„ç†å¥½çš„ã€ç»“æ„åŒ–çš„æ•°æ®ï¼Œå®ç°äº†è¯»å†™åˆ†ç¦»å’Œå…³æ³¨ç‚¹åˆ†ç¦»ã€‚

### æ ‡ç­¾
#intent/build #intent/refine #flow/ready #priority/high 
#comp/engine #comp/interfaces 
#concept/sync #concept/history #scope/core #scope/api 
#ai/instruct
#task/domain/sync #task/object/ownership #task/action/implementation #task-state/continue

---

### Script

#### Acts 1: æ‰©å±• QuipuNode æ¥å£ (interfaces)

åœ¨ `QuipuNode` dataclass ä¸­å¢åŠ  `owner_id` å­—æ®µã€‚

~~~~~act
patch_file
packages/quipu-interfaces/src/quipu/core/models.py
~~~~~
~~~~~python
    # ä»å…ƒæ•°æ®æˆ–å†…å®¹ç”Ÿæˆçš„å•è¡Œæ‘˜è¦
    summary: str = ""

    # --- å›¾éå†å­—æ®µ (ç”±åŠ è½½å™¨å¡«å……) ---
    parent: Optional[QuipuNode] = None
~~~~~
~~~~~python
    # ä»å…ƒæ•°æ®æˆ–å†…å®¹ç”Ÿæˆçš„å•è¡Œæ‘˜è¦
    summary: str = ""

    # æ‰€æœ‰è€… IDï¼Œä» Git Ref æˆ–æ•°æ®åº“ä¸­å¡«å……
    owner_id: Optional[str] = None

    # --- å›¾éå†å­—æ®µ (ç”±åŠ è½½å™¨å¡«å……) ---
    parent: Optional[QuipuNode] = None
~~~~~

#### Acts 2: å‡çº§æ•°æ®åº“ Schema å’Œå†™å…¥æ–¹æ³• (engine)

æ›´æ–° `sqlite_db.py` ä»¥æ”¯æŒ `owner_id` åˆ—ã€‚

~~~~~act
patch_file
packages/quipu-engine/src/quipu/core/sqlite_db.py
~~~~~
~~~~~python
                conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS nodes (
                        commit_hash TEXT(40) PRIMARY KEY,
                        output_tree TEXT(40) NOT NULL,
                        node_type TEXT NOT NULL,
~~~~~
~~~~~python
                conn.execute(
                    """
                    CREATE TABLE IF NOT EXISTS nodes (
                        commit_hash TEXT(40) PRIMARY KEY,
                        owner_id TEXT,
                        output_tree TEXT(40) NOT NULL,
                        node_type TEXT NOT NULL,
~~~~~

~~~~~act
patch_file
packages/quipu-engine/src/quipu/core/sqlite_db.py
~~~~~
~~~~~python
    def batch_insert_nodes(self, nodes: List[Tuple]):
        """æ‰¹é‡æ’å…¥èŠ‚ç‚¹ã€‚"""
        conn = self._get_conn()
        sql = """
            INSERT OR IGNORE INTO nodes 
            (commit_hash, output_tree, node_type, timestamp, summary, generator_id, meta_json, plan_md_cache)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """
        try:
            with conn:
                conn.executemany(sql, nodes)
~~~~~
~~~~~python
    def batch_insert_nodes(self, nodes: List[Tuple]):
        """æ‰¹é‡æ’å…¥èŠ‚ç‚¹ã€‚"""
        conn = self._get_conn()
        sql = """
            INSERT OR IGNORE INTO nodes 
            (commit_hash, owner_id, output_tree, node_type, timestamp, summary, generator_id, meta_json, plan_md_cache)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        try:
            with conn:
                conn.executemany(sql, nodes)
~~~~~

#### Acts 3: å¢å¼º GitDB çš„ Ref æŸ¥è¯¢èƒ½åŠ› (engine)

ä¿®æ”¹ `get_all_ref_heads` ä»¥è¿”å› ref åç§°ï¼Œè¿™å¯¹è§£æ `owner_id` è‡³å…³é‡è¦ã€‚

~~~~~act
patch_file
packages/quipu-engine/src/quipu/core/git_db.py
~~~~~
~~~~~python
    def get_all_ref_heads(self, prefix: str) -> List[str]:
        """æŸ¥æ‰¾æŒ‡å®šå‰ç¼€ä¸‹çš„æ‰€æœ‰ ref heads å¹¶è¿”å›å…¶ commit å“ˆå¸Œã€‚"""
        res = self._run(["for-each-ref", f"--format=%(objectname)", prefix], check=False)
        if res.returncode != 0 or not res.stdout.strip():
            return []
        return res.stdout.strip().splitlines()
~~~~~
~~~~~python
    def get_all_ref_heads(self, prefix: str) -> List[Tuple[str, str]]:
        """
        æŸ¥æ‰¾æŒ‡å®šå‰ç¼€ä¸‹çš„æ‰€æœ‰ ref headsã€‚
        è¿”å› (commit_hash, ref_name) å…ƒç»„åˆ—è¡¨ã€‚
        """
        res = self._run(["for-each-ref", f"--format=%(objectname) %(refname)", prefix], check=False)
        if res.returncode != 0 or not res.stdout.strip():
            return []
        
        results = []
        for line in res.stdout.strip().splitlines():
            parts = line.split(" ", 1)
            if len(parts) == 2:
                results.append((parts[0], parts[1]))
        return results
~~~~~

#### Acts 4: é€‚é… `GitObjectHistoryReader` (engine)

ç”±äºä¸Šä¸€æ­¥ä¿®æ”¹äº† `get_all_ref_heads` çš„è¿”å›å€¼ï¼Œæˆ‘ä»¬éœ€è¦æ›´æ–°è°ƒç”¨ç‚¹ã€‚

~~~~~act
patch_file
packages/quipu-engine/src/quipu/core/git_object_storage.py
~~~~~
~~~~~python
        # Step 1: Get Commits
        all_heads = self.git_db.get_all_ref_heads("refs/quipu/")
        if not all_heads:
            return []

        log_entries = self.git_db.log_ref(all_heads)
~~~~~
~~~~~python
        # Step 1: Get Commits
        ref_tuples = self.git_db.get_all_ref_heads("refs/quipu/")
        if not ref_tuples:
            return []
        
        all_heads = list(set(t[0] for t in ref_tuples))
        log_entries = self.git_db.log_ref(all_heads)
~~~~~

#### Acts 5: é‡æ„ Hydrator ä»¥å¤„ç†æ‰€æœ‰æƒ (engine)

è¿™æ˜¯æ ¸å¿ƒä¿®æ”¹ã€‚æˆ‘ä»¬å°†é‡å†™ `Hydrator` çš„å¤§éƒ¨åˆ†é€»è¾‘ã€‚

~~~~~act
write_file
packages/quipu-engine/src/quipu/core/hydrator.py
~~~~~
~~~~~python
import json
import logging
import re
from typing import List, Dict, Set, Tuple, Optional

from .git_db import GitDB
from .sqlite_db import DatabaseManager
from .git_object_storage import GitObjectHistoryReader  # Reuse parsing logic

logger = logging.getLogger(__name__)


class Hydrator:
    """
    è´Ÿè´£å°† Git å¯¹è±¡å†å²è®°å½•åŒæ­¥ï¼ˆè¡¥æ°´ï¼‰åˆ° SQLite æ•°æ®åº“ã€‚
    """

    def __init__(self, git_db: GitDB, db_manager: DatabaseManager):
        self.git_db = git_db
        self.db_manager = db_manager
        # å¤ç”¨ Reader ä¸­çš„äºŒè¿›åˆ¶è§£æé€»è¾‘ï¼Œé¿å…ä»£ç é‡å¤
        self._parser = GitObjectHistoryReader(git_db)

    def _get_owner_from_ref(self, ref_name: str, local_user_id: str) -> Optional[str]:
        """ä» Git ref è·¯å¾„ä¸­è§£æ owner_idã€‚"""
        # åŒ¹é… remote é•œåƒ: refs/quipu/remotes/<remote_name>/<user_id>/heads/...
        remote_match = re.match(r"refs/quipu/remotes/[^/]+/([^/]+)/heads/.*", ref_name)
        if remote_match:
            return remote_match.group(1)

        # åŒ¹é… local heads
        if ref_name.startswith("refs/quipu/local/heads/"):
            return local_user_id

        return None

    def _get_missing_commits_with_owner(self, local_user_id: str) -> Dict[str, str]:
        """
        è®¡ç®— Git ä¸­å­˜åœ¨ä½† SQLite ç¼ºå¤±çš„ commitï¼Œå¹¶ç¡®å®šå…¶æ‰€æœ‰è€…ã€‚
        è¿”å› {commit_hash: owner_id} å­—å…¸ã€‚
        """
        logger.debug("æ­£åœ¨è®¡ç®—éœ€è¦è¡¥æ°´çš„ Commit åŠå…¶æ‰€æœ‰è€…...")
        ref_tuples = self.git_db.get_all_ref_heads("refs/quipu/")
        if not ref_tuples:
            return {}

        commit_to_owner: Dict[str, str] = {}
        for commit_hash, ref_name in ref_tuples:
            # ä¸€ä¸ª commit å¯èƒ½è¢«å¤šä¸ª ref æŒ‡å‘ (e.g., local å’Œ remote mirror)
            # åªè¦èƒ½ç¡®å®šä¸€ä¸ªæ‰€æœ‰è€…å³å¯ã€‚
            if commit_hash in commit_to_owner:
                continue
            
            owner_id = self._get_owner_from_ref(ref_name, local_user_id)
            if owner_id:
                commit_to_owner[commit_hash] = owner_id

        if not commit_to_owner:
            return {}

        db_hashes = self.db_manager.get_all_node_hashes()
        
        missing_commits = {
            commit: owner for commit, owner in commit_to_owner.items() if commit not in db_hashes
        }
        
        logger.info(f"å‘ç° {len(missing_commits)} ä¸ªéœ€è¦è¡¥æ°´çš„èŠ‚ç‚¹ã€‚")
        return missing_commits

    def sync(self, local_user_id: str):
        """
        æ‰§è¡Œå¢é‡è¡¥æ°´æ“ä½œã€‚
        """
        missing_commits = self._get_missing_commits_with_owner(local_user_id)
        if not missing_commits:
            logger.debug("âœ… æ•°æ®åº“ä¸ Git å†å²ä¸€è‡´ï¼Œæ— éœ€è¡¥æ°´ã€‚")
            return

        missing_hashes = list(missing_commits.keys())
        all_git_logs = self.git_db.log_ref(missing_hashes) # Log only missing commits for efficiency
        log_map = {entry["hash"]: entry for entry in all_git_logs}

        # --- æ‰¹é‡å‡†å¤‡æ•°æ® ---
        nodes_to_insert: List[Tuple] = []
        edges_to_insert: List[Tuple] = []

        # 1. æ‰¹é‡è·å– Trees
        tree_hashes = [log_map[h]["tree"] for h in missing_hashes if h in log_map]
        trees_content = self.git_db.batch_cat_file(tree_hashes)

        # 2. è§£æ Trees, æ‰¹é‡è·å– Metas
        tree_to_meta_blob: Dict[str, str] = {}
        meta_blob_hashes: List[str] = []
        for tree_hash, content_bytes in trees_content.items():
            entries = self._parser._parse_tree_binary(content_bytes)
            if "metadata.json" in entries:
                blob_hash = entries["metadata.json"]
                tree_to_meta_blob[tree_hash] = blob_hash
                meta_blob_hashes.append(blob_hash)

        metas_content = self.git_db.batch_cat_file(meta_blob_hashes)

        # 3. æ„å»ºæ’å…¥æ•°æ®
        for commit_hash in missing_hashes:
            if commit_hash not in log_map: continue
            
            log_entry = log_map[commit_hash]
            tree_hash = log_entry["tree"]
            owner_id = missing_commits[commit_hash]

            meta_blob_hash = tree_to_meta_blob.get(tree_hash)
            if not meta_blob_hash:
                logger.warning(f"è·³è¿‡ {commit_hash[:7]}: æ‰¾ä¸åˆ° metadata.json")
                continue

            meta_bytes = metas_content.get(meta_blob_hash)
            if not meta_bytes:
                logger.warning(f"è·³è¿‡ {commit_hash[:7]}: æ‰¾ä¸åˆ° metadata blob")
                continue

            output_tree = self._parser._parse_output_tree_from_body(log_entry["body"])
            if not output_tree:
                logger.warning(f"è·³è¿‡ {commit_hash[:7]}: æ‰¾ä¸åˆ° Output-Tree trailer")
                continue

            try:
                meta_data = json.loads(meta_bytes)
                nodes_to_insert.append(
                    (
                        commit_hash,
                        owner_id,
                        output_tree,
                        meta_data.get("type", "unknown"),
                        float(meta_data.get("exec", {}).get("start") or log_entry["timestamp"]),
                        meta_data.get("summary", "No summary"),
                        meta_data.get("generator", {}).get("id"),
                        meta_bytes.decode("utf-8"),
                        None,  # plan_md_cache is NULL for cold data
                    )
                )

                # å¤„ç†è¾¹å…³ç³»
                parent_hashes = log_entry["parent"].split()
                for p_hash in parent_hashes:
                    edges_to_insert.append((commit_hash, p_hash))
            except (json.JSONDecodeError, KeyError) as e:
                logger.error(f"è§£æ {commit_hash[:7]} çš„å…ƒæ•°æ®å¤±è´¥: {e}")

        # --- æ‰¹é‡å†™å…¥æ•°æ®åº“ ---
        if nodes_to_insert:
            self.db_manager.batch_insert_nodes(nodes_to_insert)
            logger.info(f"ğŸ’§ {len(nodes_to_insert)} ä¸ªèŠ‚ç‚¹å…ƒæ•°æ®å·²è¡¥æ°´ã€‚")
        if edges_to_insert:
            self.db_manager.batch_insert_edges(edges_to_insert)
            logger.info(f"ğŸ’§ {len(edges_to_insert)} æ¡è¾¹å…³ç³»å·²è¡¥æ°´ã€‚")
~~~~~

#### Acts 6: æ›´æ–° Engine çš„ `align` æ–¹æ³• (engine)

æœ€åï¼Œæˆ‘ä»¬éœ€è¦è®© `Engine.align` åœ¨è°ƒç”¨è¡¥æ°´å™¨æ—¶ï¼Œä¼ å…¥ `user_id`ã€‚

~~~~~act
patch_file
packages/quipu-engine/src/quipu/core/state_machine.py
~~~~~
~~~~~python
    def align(self) -> str:
        # å¦‚æœä½¿ç”¨ SQLiteï¼Œå…ˆè¿›è¡Œæ•°æ®è¡¥æ°´
        if self.db_manager:
            try:
                hydrator = Hydrator(self.git_db, self.db_manager)
                hydrator.sync()
            except Exception as e:
                logger.error(f"âŒ è‡ªåŠ¨æ•°æ®è¡¥æ°´å¤±è´¥: {e}", exc_info=True)

        all_nodes = self.reader.load_all_nodes()
~~~~~
~~~~~python
    def align(self) -> str:
        # å¦‚æœä½¿ç”¨ SQLiteï¼Œå…ˆè¿›è¡Œæ•°æ®è¡¥æ°´
        if self.db_manager:
            try:
                config = ConfigManager(self.root_dir)
                user_id = config.get("sync.user_id")
                if not user_id:
                    # åœ¨ align é˜¶æ®µï¼Œæˆ‘ä»¬å‡è®¾ user_id åº”è¯¥å·²ç»å­˜åœ¨ã€‚
                    # å¦‚æœä¸å­˜åœ¨ï¼ˆä¾‹å¦‚ï¼Œç”¨æˆ·ä»æœªè¿è¡Œè¿‡ syncï¼‰ï¼Œè¡¥æ°´å™¨å°†æ— æ³•æ­£ç¡®è¯†åˆ«æœ¬åœ°èŠ‚ç‚¹æ‰€æœ‰è€…ã€‚
                    # è¿™æ˜¯ä¸€ä¸ªåˆç†çš„å›é€€ï¼Œå› ä¸ºåœ¨ sync ä¹‹å‰ï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½åº”è¯¥æ˜¯æœ¬åœ°çš„ã€‚
                    logger.debug("è¡¥æ°´æ—¶æœªæ‰¾åˆ° user_idï¼Œæœ¬åœ°æ‰€æœ‰æƒå¯èƒ½æ— æ³•ç¡®å®šã€‚")
                    user_id = "unknown-local-user"

                hydrator = Hydrator(self.git_db, self.db_manager)
                hydrator.sync(local_user_id=user_id)
            except Exception as e:
                logger.error(f"âŒ è‡ªåŠ¨æ•°æ®è¡¥æ°´å¤±è´¥: {e}", exc_info=True)

        all_nodes = self.reader.load_all_nodes()
~~~~~

### ä¸‹ä¸€æ­¥å»ºè®®
æˆ‘ä»¬å·²ç»å®Œæˆäº†æ•°æ®åç«¯çš„æ”¹é€ ã€‚ç°åœ¨ï¼Œæ•°æ®åº“ï¼ˆå¦‚æœä½¿ç”¨ SQLiteï¼‰ä¸­å·²ç»åŒ…å«äº† `owner_id` ä¿¡æ¯ã€‚

ä¸‹ä¸€æ­¥æ˜¯è®©è¯»å–å’Œå±•ç¤ºå±‚èƒ½å¤Ÿåˆ©ç”¨è¿™äº›æ–°ä¿¡æ¯ã€‚æˆ‘ä»¬å°†æ‰§è¡Œä»»åŠ¡ **4.4 å’Œ 5.1**ã€‚
