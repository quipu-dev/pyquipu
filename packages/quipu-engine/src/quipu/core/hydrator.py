import json
import logging
import re
from typing import List, Dict, Set, Tuple, Optional

from .git_db import GitDB
from .sqlite_db import DatabaseManager
from .git_object_storage import GitObjectHistoryReader  # Reuse parsing logic

logger = logging.getLogger(__name__)


class Hydrator:
    """
    è´Ÿè´£å°† Git å¯¹è±¡å†å²è®°å½•åŒæ­¥ï¼ˆè¡¥æ°´ï¼‰åˆ° SQLite æ•°æ®åº“ã€‚
    """

    def __init__(self, git_db: GitDB, db_manager: DatabaseManager):
        self.git_db = git_db
        self.db_manager = db_manager
        # å¤ç”¨ Reader ä¸­çš„äºŒè¿›åˆ¶è§£æé€»è¾‘ï¼Œé¿å…ä»£ç é‡å¤
        self._parser = GitObjectHistoryReader(git_db)

    def _get_owner_from_ref(self, ref_name: str, local_user_id: str) -> Optional[str]:
        """ä» Git ref è·¯å¾„ä¸­è§£æ owner_idã€‚"""
        remote_match = re.match(r"refs/quipu/remotes/[^/]+/([^/]+)/heads/.*", ref_name)
        if remote_match:
            return remote_match.group(1)
        if ref_name.startswith("refs/quipu/local/heads/"):
            return local_user_id
        return None

    def _get_commit_owners(self, local_user_id: str) -> Dict[str, str]:
        """
        æ„å»ºä¸€ä¸ªä» commit_hash åˆ° owner_id çš„å®Œæ•´æ˜ å°„ã€‚
        é€šè¿‡ä»æ¯ä¸ªåˆ†æ”¯æœ«ç«¯å‘ä¸Šéå†å›¾æ¥ä¼ æ’­æ‰€æœ‰æƒã€‚
        """
        # 1. è·å–æ‰€æœ‰åˆ†æ”¯æœ«ç«¯ (heads) åŠå…¶ç›´æ¥æ‰€æœ‰è€…
        head_ref_tuples = self.git_db.get_all_ref_heads("refs/quipu/")
        head_owners: Dict[str, str] = {}
        for commit_hash, ref_name in head_ref_tuples:
            # ä¼˜å…ˆçº§ï¼šè¿œç¨‹æ‰€æœ‰è€… > æœ¬åœ°æ‰€æœ‰è€…ã€‚é¿å…æœ¬åœ° ref è¦†ç›–æ­£ç¡®çš„è¿œç¨‹æ‰€æœ‰è€…ã€‚
            owner_id = self._get_owner_from_ref(ref_name, local_user_id)
            if owner_id:
                if ref_name.startswith("refs/quipu/remotes"):
                    head_owners[commit_hash] = owner_id
                elif commit_hash not in head_owners:
                    head_owners[commit_hash] = owner_id

        if not head_owners:
            return {}

        # 2. è·å–å®Œæ•´çš„å†å²å›¾è°±æ—¥å¿—
        all_git_logs = self.git_db.log_ref(list(head_owners.keys()))
        log_map = {entry["hash"]: entry for entry in all_git_logs}

        # 3. ä» Heads å¼€å§‹ï¼Œé€šè¿‡å›¾éå†ä¼ æ’­æ‰€æœ‰æƒ
        final_commit_owners: Dict[str, str] = {}
        queue = list(head_owners.keys())

        # å°† head èŠ‚ç‚¹é¢„å…ˆå¡«å…¥ï¼Œä½œä¸ºéå†çš„èµ·ç‚¹
        for commit_hash in queue:
            final_commit_owners[commit_hash] = head_owners[commit_hash]

        visited = set(head_owners.keys())

        while queue:
            child_hash = queue.pop(0)
            owner = final_commit_owners.get(child_hash)
            if not owner or child_hash not in log_map:
                continue

            parent_hashes = log_map[child_hash]["parent"].split()
            for parent_hash in parent_hashes:
                if parent_hash and parent_hash not in visited:
                    final_commit_owners[parent_hash] = owner
                    visited.add(parent_hash)
                    queue.append(parent_hash)

        return final_commit_owners

    def sync(self, local_user_id: str):
        """
        æ‰§è¡Œå¢é‡è¡¥æ°´æ“ä½œã€‚
        æ­¤å®ç°ç»è¿‡é‡æ„ï¼Œä»¥ç¡®ä¿åœ¨ä»é›¶é‡å»ºæ—¶èƒ½å¤Ÿå¤„ç†å®Œæ•´çš„å†å²å›¾è°±ã€‚
        """
        # --- é˜¶æ®µ 1: å‘ç° ---
        all_ref_heads = [t[0] for t in self.git_db.get_all_ref_heads("refs/quipu/")]
        if not all_ref_heads:
            logger.debug("âœ… Git ä¸­æœªå‘ç° Quipu å¼•ç”¨ï¼Œæ— éœ€è¡¥æ°´ã€‚")
            return

        all_git_logs = self.git_db.log_ref(all_ref_heads)
        if not all_git_logs:
            logger.debug("âœ… Git ä¸­æœªå‘ç° Quipu å†å²ï¼Œæ— éœ€è¡¥æ°´ã€‚")
            return
        log_map = {entry["hash"]: entry for entry in all_git_logs}

        # 1.2 [FIXED] æ„å»ºä¸€ä¸ªè¦†ç›–æ‰€æœ‰å†å²èŠ‚ç‚¹çš„å®Œæ•´æ‰€æœ‰æƒåœ°å›¾
        commit_owners = self._get_commit_owners(local_user_id)

        # 1.3 è®¡ç®—éœ€è¦æ’å…¥çš„èŠ‚ç‚¹ (æ‰€æœ‰å†å²èŠ‚ç‚¹ - å·²åœ¨æ•°æ®åº“ä¸­çš„èŠ‚ç‚¹)
        db_hashes = self.db_manager.get_all_node_hashes()
        missing_hashes = set(log_map.keys()) - db_hashes

        if not missing_hashes:
            logger.debug("âœ… æ•°æ®åº“ä¸ Git å†å²ä¸€è‡´ï¼Œæ— éœ€è¡¥æ°´ã€‚")
            return

        logger.info(f"å‘ç° {len(missing_hashes)} ä¸ªéœ€è¦è¡¥æ°´çš„èŠ‚ç‚¹ã€‚")

        # --- é˜¶æ®µ 2: æ‰¹é‡å‡†å¤‡æ•°æ® ---
        nodes_to_insert: List[Tuple] = []
        edges_to_insert: List[Tuple] = []

        tree_hashes = [log_map[h]["tree"] for h in missing_hashes if h in log_map]
        trees_content = self.git_db.batch_cat_file(tree_hashes)

        tree_to_meta_blob: Dict[str, str] = {}
        meta_blob_hashes: List[str] = []
        for tree_hash, content_bytes in trees_content.items():
            entries = self._parser._parse_tree_binary(content_bytes)
            if "metadata.json" in entries:
                blob_hash = entries["metadata.json"]
                tree_to_meta_blob[tree_hash] = blob_hash
                meta_blob_hashes.append(blob_hash)
        metas_content = self.git_db.batch_cat_file(meta_blob_hashes)

        for commit_hash in missing_hashes:
            log_entry = log_map[commit_hash]
            tree_hash = log_entry["tree"]
            # [FIXED] ä»å®Œæ•´çš„æ˜ å°„ä¸­è·å– owner_idï¼Œä¸å†ä½¿ç”¨é”™è¯¯çš„ fallback
            owner_id = commit_owners.get(commit_hash)
            if not owner_id:
                logger.warning(f"è·³è¿‡ {commit_hash[:7]}: æ— æ³•ç¡®å®šæ‰€æœ‰è€…")
                continue

            meta_blob_hash = tree_to_meta_blob.get(tree_hash)
            if not meta_blob_hash or meta_blob_hash not in metas_content:
                logger.warning(f"è·³è¿‡ {commit_hash[:7]}: æ‰¾ä¸åˆ° metadata.json å†…å®¹")
                continue

            output_tree = self._parser._parse_output_tree_from_body(log_entry["body"])
            if not output_tree:
                logger.warning(f"è·³è¿‡ {commit_hash[:7]}: æ‰¾ä¸åˆ° Output-Tree trailer")
                continue

            try:
                meta_bytes = metas_content[meta_blob_hash]
                meta_data = json.loads(meta_bytes)
                nodes_to_insert.append(
                    (
                        commit_hash,
                        owner_id,
                        output_tree,
                        meta_data.get("type", "unknown"),
                        float(meta_data.get("exec", {}).get("start") or log_entry["timestamp"]),
                        meta_data.get("summary", "No summary"),
                        meta_data.get("generator", {}).get("id"),
                        meta_bytes.decode("utf-8"),
                        None,
                    )
                )
                for p_hash in log_entry["parent"].split():
                    if p_hash in log_map:
                        edges_to_insert.append((commit_hash, p_hash))
            except (json.JSONDecodeError, KeyError) as e:
                logger.error(f"è§£æ {commit_hash[:7]} çš„å…ƒæ•°æ®å¤±è´¥: {e}")

        # --- é˜¶æ®µ 3: æ‰¹é‡å†™å…¥æ•°æ®åº“ ---
        if nodes_to_insert:
            self.db_manager.batch_insert_nodes(nodes_to_insert)
            logger.info(f"ğŸ’§ {len(nodes_to_insert)} ä¸ªèŠ‚ç‚¹å…ƒæ•°æ®å·²è¡¥æ°´ã€‚")
        if edges_to_insert:
            self.db_manager.batch_insert_edges(edges_to_insert)
            logger.info(f"ğŸ’§ {len(edges_to_insert)} æ¡è¾¹å…³ç³»å·²è¡¥æ°´ã€‚")
