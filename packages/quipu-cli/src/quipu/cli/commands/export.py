import logging
import re
import shutil
from datetime import datetime
from pathlib import Path
from typing import Annotated, Optional, List, Dict, Set

import typer
import yaml

from .helpers import engine_context
from ..config import DEFAULT_WORK_DIR
from quipu.interfaces.models import QuipuNode
from quipu.engine.state_machine import Engine

logger = logging.getLogger(__name__)


def _sanitize_summary(summary: str) -> str:
    """å‡€åŒ–æ‘˜è¦ä»¥ç”¨ä½œå®‰å…¨çš„æ–‡ä»¶åéƒ¨åˆ†ã€‚"""
    if not summary:
        return "no-summary"
    sanitized = re.sub(r'[\\/:#\[\]|]', '_', summary)
    sanitized = re.sub(r'[\s_]+', '_', sanitized)
    return sanitized[:60]


def _generate_filename(node: QuipuNode) -> str:
    """æ ¹æ®è§„èŒƒç”Ÿæˆæ–‡ä»¶åã€‚"""
    ts = node.timestamp.strftime("%y%m%d-%H%M")
    short_hash = node.commit_hash[:7]
    sanitized_summary = _sanitize_summary(node.summary)
    return f"{ts}-{short_hash}-{sanitized_summary}.md"


def _format_frontmatter(node: QuipuNode) -> str:
    """ç”Ÿæˆ YAML Frontmatter å­—ç¬¦ä¸²ã€‚"""
    data = {
        "commit_hash": node.commit_hash, "output_tree": node.output_tree, "input_tree": node.input_tree,
        "timestamp": node.timestamp.isoformat(), "node_type": node.node_type,
    }
    if node.owner_id:
        data["owner_id"] = node.owner_id
    yaml_str = yaml.dump(data, Dumper=yaml.SafeDumper, default_flow_style=False, sort_keys=False)
    return f"---\n{yaml_str}---"


def _filter_nodes(
    nodes: List[QuipuNode], limit: Optional[int], since: Optional[str], until: Optional[str]
) -> List[QuipuNode]:
    """æ ¹æ®æ—¶é—´æˆ³å’Œæ•°é‡è¿‡æ»¤èŠ‚ç‚¹åˆ—è¡¨ã€‚"""
    filtered = nodes
    if since:
        try:
            since_dt = datetime.fromisoformat(since.replace(" ", "T"))
            filtered = [n for n in filtered if n.timestamp >= since_dt]
        except ValueError:
            raise typer.BadParameter("æ— æ•ˆçš„ 'since' æ—¶é—´æˆ³æ ¼å¼ã€‚è¯·ä½¿ç”¨ 'YYYY-MM-DD HH:MM'ã€‚")
    if until:
        try:
            until_dt = datetime.fromisoformat(until.replace(" ", "T"))
            filtered = [n for n in filtered if n.timestamp <= until_dt]
        except ValueError:
            raise typer.BadParameter("æ— æ•ˆçš„ 'until' æ—¶é—´æˆ³æ ¼å¼ã€‚è¯·ä½¿ç”¨ 'YYYY-MM-DD HH:MM'ã€‚")
    if limit is not None and limit > 0:
        filtered = filtered[:limit]
    return list(reversed(filtered))


def _generate_navbar(
    current_node: QuipuNode, exported_hashes_set: Set[str], filename_map: Dict[str, str]
) -> str:
    """ç”Ÿæˆå¯¼èˆªæ  Markdown å­—ç¬¦ä¸²ã€‚"""
    nav_links = []

    # 1. æ€»ç»“èŠ‚ç‚¹ (â†‘)
    ancestor = current_node.parent
    while ancestor:
        if ancestor.input_tree == ancestor.output_tree and ancestor.commit_hash in exported_hashes_set:
            nav_links.append(f"> â†‘ [æ€»ç»“èŠ‚ç‚¹]({filename_map[ancestor.commit_hash]})")
            break
        ancestor = ancestor.parent

    # 2. ä¸Šä¸€åˆ†æ”¯ç‚¹ (â†“)
    ancestor = current_node.parent
    while ancestor:
        if len(ancestor.children) > 1 and ancestor.commit_hash in exported_hashes_set:
            nav_links.append(f"> â†“ [ä¸Šä¸€åˆ†æ”¯ç‚¹]({filename_map[ancestor.commit_hash]})")
            break
        ancestor = ancestor.parent

    # 3. çˆ¶èŠ‚ç‚¹ (â†)
    if current_node.parent and current_node.parent.commit_hash in exported_hashes_set:
        nav_links.append(f"> â† [çˆ¶èŠ‚ç‚¹]({filename_map[current_node.parent.commit_hash]})")

    # 4. å­èŠ‚ç‚¹ (â†’)
    # å­èŠ‚ç‚¹å·²æŒ‰æ—¶é—´å‡åºæ’åˆ—
    for child in current_node.children:
        if child.commit_hash in exported_hashes_set:
            nav_links.append(f"> â†’ [å­èŠ‚ç‚¹]({filename_map[child.commit_hash]})")

    if not nav_links:
        return ""
    
    return "\n\n" + "> [!nav] èŠ‚ç‚¹å¯¼èˆª\n" + "\n".join(nav_links)


def _generate_file_content(
    node: QuipuNode, engine: Engine, no_frontmatter: bool, no_nav: bool,
    exported_hashes_set: Set[str], filename_map: Dict[str, str]
) -> str:
    """æ„å»ºå•ä¸ª Markdown æ–‡ä»¶çš„å®Œæ•´å†…å®¹ã€‚"""
    parts = []
    if not no_frontmatter:
        parts.append(_format_frontmatter(node))

    public_content = engine.reader.get_node_content(node) or ""
    parts.append("# content.md")
    parts.append(public_content.strip())

    private_content = engine.reader.get_private_data(node.commit_hash)
    if private_content:
        parts.append("# å¼€å‘è€…æ„å›¾")
        parts.append(private_content.strip())
        
    content_str = "\n\n".join(parts)

    if not no_nav:
        navbar_str = _generate_navbar(node, exported_hashes_set, filename_map)
        content_str += navbar_str
        
    return content_str


def register(app: typer.Typer):
    @app.command(name="export")
    def export_command(
        ctx: typer.Context,
        work_dir: Annotated[Path, typer.Option("--work-dir", "-w", help="å·¥ä½œåŒºæ ¹ç›®å½•", resolve_path=True)] = DEFAULT_WORK_DIR,
        output_dir: Annotated[Path, typer.Option("--output-dir", "-o", help="å¯¼å‡ºç›®å½•", resolve_path=True)] = Path("./.quipu/export"),
        limit: Annotated[Optional[int], typer.Option("--limit", "-n", help="é™åˆ¶æœ€æ–°èŠ‚ç‚¹æ•°é‡")] = None,
        since: Annotated[Optional[str], typer.Option("--since", help="èµ·å§‹æ—¶é—´æˆ³ (YYYY-MM-DD HH:MM)")] = None,
        until: Annotated[Optional[str], typer.Option("--until", help="æˆªæ­¢æ—¶é—´æˆ³ (YYYY-MM-DD HH:MM)")] = None,
        zip_output: Annotated[bool, typer.Option("--zip", help="å‹ç¼©å¯¼å‡ºç›®å½•")] = False,
        no_nav: Annotated[bool, typer.Option("--no-nav", help="ç¦ç”¨å¯¼èˆªæ ")] = False,
        no_frontmatter: Annotated[bool, typer.Option("--no-frontmatter", help="ç¦ç”¨ Frontmatter")] = False,
    ):
        """å°† Quipu å†å²è®°å½•å¯¼å‡ºä¸ºä¸€ç»„äººç±»å¯è¯»çš„ Markdown æ–‡ä»¶ã€‚"""
        with engine_context(work_dir) as engine:
            if not engine.history_graph:
                typer.secho("ğŸ“œ å†å²è®°å½•ä¸ºç©ºï¼Œæ— éœ€å¯¼å‡ºã€‚", fg=typer.colors.YELLOW, err=True); ctx.exit(0)

            all_nodes = sorted(engine.history_graph.values(), key=lambda n: n.timestamp, reverse=True)
            try:
                nodes_to_export = _filter_nodes(all_nodes, limit, since, until)
            except typer.BadParameter as e:
                typer.secho(f"âŒ å‚æ•°é”™è¯¯: {e}", fg=typer.colors.RED, err=True); ctx.exit(1)

            if not nodes_to_export:
                typer.secho("ğŸ¤· æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹ã€‚", fg=typer.colors.YELLOW, err=True); ctx.exit(0)

            if output_dir.exists() and any(output_dir.iterdir()):
                if not typer.confirm(f"âš ï¸ ç›®å½• '{output_dir}' éç©ºï¼Œæ˜¯å¦æ¸…ç©ºå¹¶ç»§ç»­?", abort=True):
                    return
                shutil.rmtree(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            typer.secho(f"ğŸš€ æ­£åœ¨å¯¼å‡º {len(nodes_to_export)} ä¸ªèŠ‚ç‚¹åˆ° '{output_dir}'...", fg=typer.colors.BLUE, err=True)

            # é¢„è®¡ç®—æ–‡ä»¶åå’ŒèŠ‚ç‚¹é›†åˆä»¥ä¾›å¯¼èˆªæ ä½¿ç”¨
            filename_map = {node.commit_hash: _generate_filename(node) for node in nodes_to_export}
            exported_hashes_set = {node.commit_hash for node in nodes_to_export}

            with typer.progressbar(nodes_to_export, label="å¯¼å‡ºè¿›åº¦") as progress:
                for node in progress:
                    filename = filename_map[node.commit_hash]
                    content = _generate_file_content(node, engine, no_frontmatter, no_nav, exported_hashes_set, filename_map)
                    (output_dir / filename).write_text(content, encoding="utf-8")

            if zip_output:
                typer.secho("ğŸ“¦ æ­£åœ¨å‹ç¼©å¯¼å‡ºæ–‡ä»¶...", fg=typer.colors.BLUE, err=True)
                zip_path = shutil.make_archive(str(output_dir), 'zip', output_dir)
                shutil.rmtree(output_dir)
                typer.secho(f"\nâœ… å¯¼å‡ºæˆåŠŸï¼Œå·²ä¿å­˜ä¸ºå‹ç¼©åŒ…: {zip_path}", fg=typer.colors.GREEN, err=True)
            else:
                typer.secho(f"\nâœ… å¯¼å‡ºæˆåŠŸå®Œæˆã€‚", fg=typer.colors.GREEN, err=True)